                                    Practical Data Science, A3
                                  Vasileios Ilias Drouzas, ID: f3352301
                                  
This is the readme.md file, where you can find general instructions about the 1)Data Formation, 2)LLM prompts and 3)general comments on the calculation process of scores etc.

1.	Data Formation
Most of the data was generated using the code we showed in class, via the generate_text() function and some of them via prompting ChatGPT. The format of the augmentation.csv file is the following: 

(id, prompt_id, text, generated, sent, LLM essay, cluster),  where:
Id: ID of the essay
prompt_id: Indicates the type of essay (0: cars, 1: cities)
text: Contains the whole essay
generated: binary variable indicating whether it was generated by an LLM or it is an authentic one by a student (0: student essay, 1: LLM essay)
sent: Contains each sentence of the essay in ‘text’
Cluster: the cluster to which the particular essay is assigned

2.	LLM prompts 
The prompt I used to get the data was:
Cars use case:
 
You
Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Repeat this procedure 100 times.
ChatGPT
ChatGPT
I'm unable to fulfill your request for 100 unique multiparagraph essays due to time and space limitations. However, I can certainly provide an exemplary essay on the advantages of limiting car usage, drawing information from various sources and presenting a well-structured, informative piece. Please find the essay below:
Title: Embracing the Benefits of Reducing Car Dependency
As urban landscapes evolve and environmental concerns heighten, the advantages of limiting car usage have become increasingly apparent. While cars have undoubtedly provided convenience and mobility, their excessive use poses challenges ranging from environmental degradation to societal issues. By embracing alternatives and reducing our reliance on automobiles, we can pave the way for numerous benefits, including improved air quality, enhanced public health, reduced congestion, and a shift toward sustainable living.
One significant advantage of limiting car usage lies in the positive impact on the environment. Studies by the World Health Organization (WHO) highlight how vehicular emissions contribute significantly to air pollution, leading to respiratory diseases and environmental degradation. Embracing alternative modes of transportation, such as cycling, walking, or using public transit, can significantly reduce carbon emissions, curbing pollution levels and safeguarding the environment.
Moreover, reducing car dependency can have profound implications for public health. Research published in reputable journals like The Lancet emphasizes the detrimental health effects of sedentary lifestyles associated with excessive car use. By encouraging walking or cycling for shorter distances, individuals can incorporate physical activity into their daily routines, promoting better cardiovascular health and reducing the risk of chronic illnesses like obesity and diabetes.
Another compelling advantage is the alleviation of traffic congestion. Reports from transportation authorities globally indicate that a significant portion of traffic congestion is attributed to single-occupancy vehicles. Implementing measures such as carpooling, promoting public transit systems, and embracing shared mobility services can effectively reduce the number of vehicles on the roads, thus mitigating congestion and improving overall traffic flow.
Furthermore, limiting car usage aligns with the transition towards sustainable living. Reports from environmental organizations like the Intergovernmental Panel on Climate Change (IPCC) stress the urgency of adopting sustainable practices to combat climate change. Embracing public policies that encourage the use of electric vehicles, incentivize carpooling, and prioritize investments in public transportation infrastructure can collectively contribute to a more sustainable future.
In conclusion, the advantages of limiting car usage are multifaceted and far-reaching. From mitigating environmental degradation and improving public health to reducing traffic congestion and fostering sustainability, the benefits are undeniable. By collectively embracing alternative transportation methods and rethinking our reliance on cars, we can pave the way for a more sustainable and healthier future for generations to come.
Remember, this is a sample essay crafted within a limited space. Creating unique, high-quality essays multiple times may not be feasible due to constraints. If you need more specific information or further guidance, feel free to ask!

Cities use case:
 
You
Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to include a claim; address counterclaims; use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay.
ChatGPT
ChatGPT
Dear [State Senator's Name],
I am writing to urge you to carefully consider the fundamental aspect of the Electoral College in our presidential elections. The Electoral College has been a longstanding institution in American democracy, but debates persist regarding its efficacy and relevance in modern times. While some advocate for retaining this system, arguing for its ability to preserve federalism and protect smaller states' interests, others support a shift towards a popular vote, emphasizing the principles of fairness, equality, and the direct expression of citizens' will.
One of the central arguments in favor of maintaining the Electoral College lies in its preservation of the interests of smaller states. Proponents argue that the Electoral College ensures that candidates must appeal to a broad coalition of states, preventing the domination of politics by heavily populated urban centers and granting a voice to less populous regions. As noted by Alexander Hamilton in Federalist Paper No. 68, the Electoral College acts as a safeguard against potential demagoguery and the influence of factions, fostering stability and preventing the rise of candidates who may merely pander to the majority without considering the diverse needs of the entire nation.
However, the call for reform toward a popular vote system also bears weighty arguments. The Electoral College's winner-takes-all approach in most states often leads to candidates focusing their efforts on swing states, neglecting the concerns of those in reliably red or blue states. This results in a significant portion of the electorate feeling disenfranchised, as their votes might seem inconsequential in the final outcome. Furthermore, instances where the winner of the popular vote loses the electoral vote, as seen in multiple elections, raise questions about the system's democratic legitimacy.
Proponents of the popular vote argue that it aligns more closely with the democratic principle of "one person, one vote," ensuring that every vote cast carries equal weight regardless of geographic location. Advocates, such as those in the National Popular Vote movement, suggest an interstate compact where states pledge their electoral votes to the winner of the national popular vote, thereby circumventing the need for a constitutional amendment while achieving a more direct representation of the people's choice.
While both systems possess merits and drawbacks, a careful analysis of the current political landscape and its impact on the American electorate is imperative. Perhaps a compromise that integrates elements from both systems could offer a solution that addresses concerns about representation while preserving the integrity of our federalist system.
In conclusion, the debate over the Electoral College versus a popular vote system is multifaceted, requiring a comprehensive assessment of its implications on our democracy. It is my hope that as our representative, you will consider these arguments thoughtfully and engage in initiatives that ensure fair representation and uphold the democratic values of our nation.
Thank you for your time and dedication to serving our state.
The LLM did never return more than one essay, so I had to repeat this process iteratively. I reached a point of 107 essays for both use cases with this method.


3.	General comments

All the data (LLM and student generated) for the cars (cities) use case are stored in the augmented_data0 (augmented_data1) dataframe.
A.	 At first, we benchmarked several classification algorithms (Logistic Regression, Naïve Bayes, K Nearest Neighbors (KNN), Decision Tree and Random Forest. The last one proved to be the best performing one.

B.	To compute the maximum similarity scores between the LLM generated essays and the student essays, we used the cosine_similarity metric. First of all, we initialized a TFIDF vectorizer and applied the fit_transform() function for the student essays (tfidf_matrix). Iterating through the LLM essays, we took the transformed type of it (text_idf) and we calculated the cosine similarity score between the tfidf_matrix and the text_idf. Finally, to calculate the maximum similarity, we simply used the numpy.max() function and for the average similarity, the numpy.mean().


C.	For the probability scores: 1) tfidf_matrix included all essays, 2) Iterating the LLM essays, we kept the training indexes as a whole list of the range of all essays and in which we removed the element in the current index of the iteration (which served as the test index). So the training data were formed by using these indexes. 3) the labels were formed in the same way, firstly by filling 1s for the length of the LLM essays, then 0s for the student essays and discarding the current element. After all of these, we fitted the algorithm and used the predict_proba() function to give us the prediction probabilities for every test instance.

D.	Regarding the relation between the max/avg similarities and the prediction probabilities, we calculated the correlation coefficient between these two and plotted each case. The coefficients were found to be 1) for the max similarities case, highly negative (approx. -0.6) indicating a contrary relationship and 2) for the avg similarities case, mildly negative (approx.. -0.4). The Spearman and Pearson coefficients yielded similar results.


E.	To decide which generated texts to discard: We simply decided to put a threshold only for the prediction probabilities (0.6), and thus remove all the indexes that had a smaller pred. prob. (removing the less “certain” values for our classifier). The algorithm performed similarly as before, because the number of essays discarded was not big (we did not want at this point to create a class imbalance).

F.	Learning curves: Plotting the learning curves, we notice that our classifier gives accuracy 1 (perfect) for the training data for each portion. The test dataset accuracy increments as the training size gets bigger. In most cases, this would be a concern of overfitting, but in our case, it means that our classifier has learned perfectly from the data we trained it to and thinking that it has already been trained on these ones that it is being tested, the accuracy rates are not a very big surprise.

G.	Clustering: Here, we determined the optimum number of clusters via the Elbow method (which though did not clearly reveal the best K). After that, we formed our clusters. The process to generate the titles was: firstly we took all the text from each cluster, we removed all the stop words (via the NLTK package) and used regular expressions to remove also some special characters that affected our result (e.g. dots, commas). After filtering, we used the FreqDist() function and found the most common words, which formed the title for each cluster. In addition, to find the similarity scores between clusterings, we used again the cosine_similarity metric. Now, in order to balance the clusters evenly, we iterated through the clusters, found the cluster with the maximum number of elements and kept the difference of elements from the current cluster and the maximum count. Then all we had to do was fill the remaining clusters with this difference count. After doing that, the LLM generated texts were minorly incremented. Finally, after running our algorithm again for the new data, we good similar performance and CV scores to before (achieving though not to disbalance the classes, since we did not produce a lot of new data).

